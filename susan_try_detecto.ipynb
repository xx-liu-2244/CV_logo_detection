{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure:\n",
    "- to be in the same directory as the folder where the images and annotations are\n",
    "- to have installed `detecto` in the environment\n",
    "\n",
    "Note: change file names and paths where needed for your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_name = os.listdir('train') #folder with all the images\n",
    "annot_data = pd.read_csv('annot_train.csv') #original csv file with all the annotations\n",
    "len(files_name), len(annot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out the annotations for images that are not present in the image folder\n",
    "new_annot_data = annot_data[annot_data.photo_filename.isin(files_name)]\n",
    "\n",
    "#adding column 'image_id' in the annotations as per requirement of detecto model\n",
    "new_annot_data['image_id'] = [i for i in range(1, len(files_name)+1)]\n",
    "\n",
    "#replace all the classes that are not one of the 5 compulsory logos\n",
    "logos = ['Nike','Adidas','Under Armour','Puma','The North Face']\n",
    "new_annot_data.loc[~new_annot_data['class'].isin(logos),'class'] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train and test sets, 80% and 20%. Based on that, creating annotations for the respective image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "for f in files_name:\n",
    "    if np.random.rand(1) < 0.2:\n",
    "        shutil.move('train/'+f, 'test/'+f)  #make sure to have already created 'test' folder in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting file names in each folder\n",
    "train_files = os.listdir('train')\n",
    "test_files = os.listdir('test')\n",
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting annotations only for train set images\n",
    "annot_train = new_annot_data[new_annot_data.photo_filename.isin(train_files)]\n",
    "annot_train.to_csv(r'annot_train.csv', index=False, header=True) #choose the output path to store the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting annotations only for test set images\n",
    "annot_test = new_annot_data[new_annot_data.photo_filename.isin(test_files)]\n",
    "annot_test.to_csv(r'annot_test.csv', index=False, header=True)  #choose the output path to store the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the csv are of the same length as the number of image files\n",
    "len(annot_train), len(annot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecto\n",
    "Ref: https://towardsdatascience.com/build-a-custom-trained-object-detection-model-with-5-lines-of-code-713ba7f6c0fb\n",
    "Documentation: https://detecto.readthedocs.io/en/latest/api/core.html#detecto.core.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detecto import core, utils, visualize\n",
    "from torchvision import transforms #torchvision is installed together with detecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(900),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(saturation=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    utils.normalize_transform(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the files and folder names/paths depending on where those are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = core.Dataset(label_data='annot_train.csv',image_folder='train',transform=augmentations)\n",
    "loader = core.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "model = core.Model(classes=['Nike', 'Adidas', 'Under Armour', 'Puma', 'The North Face','Other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stopped here because I had a `RuntimeError`:\n",
    "\n",
    "```python\n",
    "RuntimeError: CUDA error: out of memory\n",
    "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
    "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
    "```\n",
    "\n",
    "Below should be the next steps to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset,epochs=8, learning_rate=0.005,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the model and the current progress to come back to it later:\n",
    "```python\n",
    "model.save('model_weights.pth')```\n",
    "\n",
    "To load the model from files:\n",
    "```python\n",
    "model = core.Model.load('model_weights.pth', ['Nike', 'Adidas', 'Under Armour', 'Puma', 'The North Face','Other'])```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `predict_top` returns the top scoring predictions for each detected label in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detecto.utils import read_image\n",
    "\n",
    "#need to finda way to predict an entire folder of test images\n",
    "image = read_image('image.jpg') #example\n",
    "top_preds = model.predict_top(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: calculate the IoU on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
